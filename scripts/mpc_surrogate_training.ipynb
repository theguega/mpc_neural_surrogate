{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC Surrogate Training Pipeline\n",
    "\n",
    "This notebook implements the complete training and evaluation pipeline for approximating MPC policies using neural networks.\n",
    "\n",
    "## Dataset Structure\n",
    "- **States**: Joint positions and velocities (6D) - [q1, q2, q3, q̇1, q̇2, q̇3]\n",
    "- **Targets**: End-effector target positions (3D) - [x, y, z]\n",
    "- **Actions**: MPC torques (3D) - [τ1, τ2, τ3]\n",
    "\n",
    "The goal is to learn a mapping: (state, target) → MPC torques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install h5py numpy matplotlib scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_PATH = 'data/robot_mpc_dataset.h5'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation - Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPCDataset(Dataset):\n",
    "    def __init__(self, filepath, episode_keys, mode=\"mlp\", augment=False):\n",
    "        \"\"\"\n",
    "        mode: 'mlp' (flattens trajectories) or 'rnn' (keeps trajectories intact)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data = []  # (inputs, actions) tuples\n",
    "\n",
    "        with h5py.File(filepath, \"r\") as f:\n",
    "            grp_eps = f[\"episodes\"]\n",
    "            for ep in episode_keys:\n",
    "                # Load raw data\n",
    "                s = torch.from_numpy(grp_eps[ep][\"states\"][:]).float()  # (T, 6)\n",
    "                t = torch.from_numpy(grp_eps[ep][\"targets\"][:]).float()  # (T, 3)\n",
    "                a = torch.from_numpy(grp_eps[ep][\"actions\"][:]).float()  # (T, 3)\n",
    "\n",
    "                # states + targets as input -> (T, 9)\n",
    "                inp = torch.cat([s, t], dim=-1)\n",
    "                self.data.append((inp, a))\n",
    "\n",
    "        # if MLP, flatten all steps from these specific episodes into one tensor\n",
    "        if self.mode == \"mlp\":\n",
    "            self.inputs = torch.cat([x[0] for x in self.data], dim=0)\n",
    "            self.actions = torch.cat([x[1] for x in self.data], dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs) if self.mode == \"mlp\" else len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"mlp\":\n",
    "            x, y = self.inputs[idx], self.actions[idx]  # (9,), (3,)\n",
    "            if self.augment:\n",
    "                x[:6] += torch.randn(6) * 0.01  # noise on state\n",
    "                y += torch.randn(3) * 0.005  # noise on action\n",
    "            return x, y\n",
    "\n",
    "        # RNN\n",
    "        else:\n",
    "            x, y = self.data[idx]  # (T, 9), (T, 3)\n",
    "            if self.augment:\n",
    "                noise_x = torch.randn_like(x)\n",
    "                noise_x[:, 6:] = 0  # no noise on targets\n",
    "                x = x + (noise_x * 0.01)\n",
    "                y = y + (torch.randn_like(y) * 0.005)\n",
    "            return x, y\n",
    "\n",
    "\n",
    "def collate_rnn(batch):\n",
    "    inputs, actions = zip(*batch)\n",
    "    lengths = torch.tensor([x.size(0) for x in inputs])\n",
    "\n",
    "    # pad variable lengths (T0, T1...) to max length in batch\n",
    "    padded_inputs = pad_sequence(inputs, batch_first=True)  # (B, T_max, 9)\n",
    "    padded_actions = pad_sequence(actions, batch_first=True)  # (B, T_max, 3)\n",
    "\n",
    "    return padded_inputs, padded_actions, lengths\n",
    "\n",
    "\n",
    "def create_dataloaders(filepath, train_ratio=0.8, batch_size=32):\n",
    "    # split by episode idx\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        keys = np.array(sorted(f[\"episodes\"].keys()))\n",
    "\n",
    "    np.random.shuffle(keys)\n",
    "    split = int(len(keys) * train_ratio)\n",
    "    train_keys, val_keys = keys[:split], keys[split:]\n",
    "\n",
    "    train_ds_mlp = MPCDataset(filepath, train_keys, mode=\"mlp\", augment=True)\n",
    "    val_ds_mlp = MPCDataset(filepath, val_keys, mode=\"mlp\", augment=False)\n",
    "\n",
    "    train_ds_rnn = MPCDataset(filepath, train_keys, mode=\"rnn\", augment=True)\n",
    "    val_ds_rnn = MPCDataset(filepath, val_keys, mode=\"rnn\", augment=False)\n",
    "\n",
    "    tl_mlp = DataLoader(train_ds_mlp, batch_size=batch_size, shuffle=True)\n",
    "    vl_mlp = DataLoader(val_ds_mlp, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    tl_rnn = DataLoader(train_ds_rnn, batch_size=batch_size, shuffle=True, collate_fn=collate_rnn)\n",
    "    vl_rnn = DataLoader(val_ds_rnn, batch_size=batch_size, shuffle=False, collate_fn=collate_rnn)\n",
    "\n",
    "    return tl_mlp, vl_mlp, tl_rnn, vl_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'mpc_surrogate (Python 3.12.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/theguega/Developer/waterloo/mpc_surrogate/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "episodes = []\n",
    "with h5py.File(\"robot_mpc_dataset.h5\", \"r\") as f:\n",
    "    keys = np.array(sorted(f[\"episodes\"].keys()))\n",
    "    for ep in keys:\n",
    "        grp = f[\"episodes\"][ep]\n",
    "        states = grp[\"states\"][:]\n",
    "        targets = grp[\"targets\"][:]\n",
    "        actions = grp[\"actions\"][:]\n",
    "        episodes.append((states, targets, actions))\n",
    "\n",
    "# pick a random episode\n",
    "ep_idx = random.randint(0, len(episodes) - 1)\n",
    "episode = episodes[ep_idx]\n",
    "ep_states = episode[0]\n",
    "ep_targets = episode[1]\n",
    "ep_actions = episode[2]\n",
    "\n",
    "print(f\"Visualizing episode {ep_idx}\")\n",
    "\n",
    "# joint positions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(ep_states[:, 0], label=\"q1\")\n",
    "plt.plot(ep_states[:, 1], label=\"q2\")\n",
    "plt.plot(ep_states[:, 2], label=\"q3\")\n",
    "plt.title(\"Joint Positions\")\n",
    "plt.legend()\n",
    "\n",
    "# joint velocities\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(ep_states[:, 3], label=\"dq1\")\n",
    "plt.plot(ep_states[:, 4], label=\"dq2\")\n",
    "plt.plot(ep_states[:, 5], label=\"dq3\")\n",
    "plt.title(\"Joint Velocities\")\n",
    "plt.legend()\n",
    "\n",
    "# MPC actions\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(ep_actions[:, 0], label=\"tau1\")\n",
    "plt.plot(ep_actions[:, 1], label=\"tau2\")\n",
    "plt.plot(ep_actions[:, 2], label=\"tau3\")\n",
    "plt.title(\"MPC Torques\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATASET\n",
    "# episodes/ep_xxxx/{states, targets, actions}.npy\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def load_dataset(root=\"episodes\"):\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for ep in tqdm(sorted(glob.glob(os.path.join(root, \"ep_*\")))):\n",
    "        states = np.load(os.path.join(ep, \"states.npy\"))  # (T, 6)\n",
    "        targets = np.load(os.path.join(ep, \"targets.npy\"))  # (T, 3)\n",
    "        actions = np.load(os.path.join(ep, \"actions.npy\"))  # (T, 3)\n",
    "\n",
    "        X = np.concatenate([states, targets], axis=1)  # (T, 9)\n",
    "        y = actions  # (T, 3)\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "\n",
    "    X = np.vstack(X_list)\n",
    "    y = np.vstack(y_list)\n",
    "\n",
    "    print(\"Loaded dataset:\")\n",
    "    print(\"X:\", X.shape, \"  y:\", y.shape)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = load_dataset(\"episodes\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Split + Normalize\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Baseline Models\n",
    "# ============================================================\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=1e-3),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=200, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"SVM (RBF)\": MultiOutputRegressor(SVR(kernel=\"rbf\", C=10, gamma=\"scale\")),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"\\n===== TRAINING BASELINES =====\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    results[name] = mse\n",
    "    print(f\"{name} MSE: {mse:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n==== FINAL RESULTS ====\")\n",
    "for name, mse in results.items():\n",
    "    print(f\"{name:20s}: MSE = {mse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple Multi-Layer Perceptron\"\"\"\n",
    "    def __init__(self, input_dim=9, hidden_dims=[128, 64], output_dim=3):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.Dropout(0.1)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.linear1 = nn.Linear(dim, dim)\n",
    "        self.linear2 = nn.Linear(dim, dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.linear1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"Residual Network for MPC surrogate\"\"\"\n",
    "    def __init__(self, input_dim=9, hidden_dim=128, num_blocks=3, output_dim=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.res_blocks = nn.ModuleList([ResidualBlock(hidden_dim) for _ in range(num_blocks)])\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.input_layer(x))\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, ff_dim=None):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        if ff_dim is None:\n",
    "            ff_dim = 4 * dim\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(ff_dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Self-attention\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "\n",
    "        # Feed-forward\n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm2(x + ff_out)\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformer-based MPC surrogate\"\"\"\n",
    "    def __init__(self, input_dim=9, embed_dim=64, num_heads=4, num_blocks=2, output_dim=3):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add batch and sequence dimensions for transformer\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)  # [batch, 1, features]\n",
    "\n",
    "        x = self.input_embedding(x)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "        x = x.squeeze(1)  # Remove sequence dimension\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Model configurations\n",
    "model_configs = {\n",
    "    'MLP': {'class': MLP, 'params': {'hidden_dims': [128, 64]}},\n",
    "    'ResNet': {'class': ResNet, 'params': {'hidden_dim': 128, 'num_blocks': 3}},\n",
    "    'Transformer': {'class': Transformer, 'params': {'embed_dim': 64, 'num_heads': 4, 'num_blocks': 2}}\n",
    "}\n",
    "\n",
    "print(\"Available models:\", list(model_configs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(all_predictions)\n",
    "    targets = np.concatenate(all_targets)\n",
    "\n",
    "    mse = mean_squared_error(targets, predictions)\n",
    "    mae = mean_absolute_error(targets, predictions)\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / num_batches,\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'predictions': predictions,\n",
    "        'targets': targets\n",
    "    }\n",
    "\n",
    "def train_model(model_name, model, train_loader, test_loader, num_epochs=100, patience=10):\n",
    "    \"\"\"Complete training pipeline for a model\"\"\"\n",
    "    print(f\"\\n=== Training {model_name} ===\")\n",
    "\n",
    "    # Loss functions\n",
    "    mse_criterion = nn.MSELoss()\n",
    "    mae_criterion = nn.L1Loss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    # Schedulers\n",
    "    mse_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    mae_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'hyperparameters': {\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'batch_size': train_loader.batch_size,\n",
    "            'num_epochs': num_epochs\n",
    "        },\n",
    "        'training_history': [],\n",
    "        'best_mse_results': None,\n",
    "        'best_mae_results': None\n",
    "    }\n",
    "\n",
    "    best_mse_loss = float('inf')\n",
    "    best_mae_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train with MSE\n",
    "        train_loss_mse = train_epoch(model, train_loader, mse_criterion, optimizer)\n",
    "        mse_results = evaluate(model, test_loader, mse_criterion)\n",
    "\n",
    "        # Train with MAE\n",
    "        train_loss_mae = train_epoch(model, train_loader, mae_criterion, optimizer)\n",
    "        mae_results = evaluate(model, test_loader, mae_criterion)\n",
    "\n",
    "        # Update schedulers\n",
    "        mse_scheduler.step(mse_results['loss'])\n",
    "        mae_scheduler.step(mae_results['loss'])\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # Log results\n",
    "        epoch_results = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss_mse': train_loss_mse,\n",
    "            'test_loss_mse': mse_results['loss'],\n",
    "            'test_mse': mse_results['mse'],\n",
    "            'test_mae': mse_results['mae'],\n",
    "            'train_loss_mae': train_loss_mae,\n",
    "            'test_loss_mae': mae_results['loss'],\n",
    "            'epoch_time': epoch_time\n",
    "        }\n",
    "        results['training_history'].append(epoch_results)\n",
    "\n",
    "        # Save best models\n",
    "        if mse_results['loss'] < best_mse_loss:\n",
    "            best_mse_loss = mse_results['loss']\n",
    "            results['best_mse_results'] = mse_results.copy()\n",
    "            torch.save(model.state_dict(), f'{model_name}_best_mse.pth')\n",
    "\n",
    "        if mae_results['loss'] < best_mae_loss:\n",
    "            best_mae_loss = mae_results['loss']\n",
    "            results['best_mae_results'] = mae_results.copy()\n",
    "            torch.save(model.state_dict(), f'{model_name}_best_mae.pth')\n",
    "\n",
    "        # Early stopping\n",
    "        if mse_results['loss'] >= best_mse_loss:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            patience_counter = 0\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {mse_results['loss']:.6f}, MAE Loss: {mae_results['loss']:.6f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACT Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim=6,  # qpos + qvel (e.g., 3 pos + 3 vel)\n",
    "        target_dim=3,  # Cartesian goal (x,y,z)\n",
    "        action_dim=3,  # torque output (3 DoF)\n",
    "        latent_dim=512,\n",
    "        num_layers=6,\n",
    "        nhead=8,\n",
    "        dim_feedforward=1024,\n",
    "        dropout=0.1,\n",
    "        temporal_chunk_size=32,  # how many timesteps per chunk (paper uses 32–100)\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temporal_chunk_size = temporal_chunk_size\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Input embedding\n",
    "        self.state_encoder = nn.Linear(state_dim, latent_dim)\n",
    "        self.target_encoder = nn.Linear(target_dim, latent_dim)\n",
    "\n",
    "        # Positional encoding (sinusoidal)\n",
    "        self.pos_encoder = PositionalEncoding(latent_dim, dropout)\n",
    "\n",
    "        # Transformer Encoder (ACT uses encoder-only)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=latent_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Action head\n",
    "        self.action_head = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim), nn.GELU(), nn.Linear(latent_dim, action_dim)\n",
    "        )\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, states, targets):\n",
    "        \"\"\"\n",
    "        states : (B, T, state_dim)      -> current joint pos/vel\n",
    "        targets: (B, T, target_dim)     -> same goal repeated (from your data)\n",
    "        Returns:\n",
    "            actions: (B, T, action_dim)\n",
    "        \"\"\"\n",
    "        B, T, _ = states.shape\n",
    "\n",
    "        # Encode inputs\n",
    "        state_emb = self.state_encoder(states)  # (B,T,latent)\n",
    "        target_emb = self.target_encoder(targets)  # (B,T,latent)\n",
    "\n",
    "        x = state_emb + target_emb  # goal-conditioned embedding\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # Apply transformer\n",
    "        x = self.transformer(x)  # (B,T,latent)\n",
    "\n",
    "        # Predict actions\n",
    "        actions = self.action_head(x)  # (B,T,action_dim)\n",
    "\n",
    "        return actions\n",
    "\n",
    "    def get_chunked_loss(self, states, targets, actions_true, chunk_size=None):\n",
    "        \"\"\"\n",
    "        ACT trains on random temporal chunks (key to good performance!)\n",
    "        \"\"\"\n",
    "        if chunk_size is None:\n",
    "            chunk_size = self.temporal_chunk_size\n",
    "\n",
    "        B, T, _ = states.shape\n",
    "        max_start = T - chunk_size\n",
    "\n",
    "        if max_start <= 0:\n",
    "            return nn.functional.mse_loss(self(states, targets), actions_true)\n",
    "\n",
    "        # Random temporal chunk per batch element\n",
    "        start_idx = torch.randint(0, max_start + 1, (B,))\n",
    "        idxs = start_idx.unsqueeze(1) + torch.arange(chunk_size).unsqueeze(0).to(states.device)\n",
    "\n",
    "        s_chunk = torch.gather(states, 1, idxs.unsqueeze(-1).expand(-1, -1, states.size(-1)))\n",
    "        t_chunk = torch.gather(targets, 1, idxs.unsqueeze(-1).expand(-1, -1, targets.size(-1)))\n",
    "        a_chunk = torch.gather(actions_true, 1, idxs.unsqueeze(-1).expand(-1, -1, actions_true.size(-1)))\n",
    "\n",
    "        a_pred = self(s_chunk, t_chunk)\n",
    "        return nn.functional.mse_loss(a_pred, a_chunk)\n",
    "\n",
    "\n",
    "# Positional encoding (same as ACT / original Transformer)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACT(\n",
    "    state_dim=6, target_dim=3, action_dim=3, latent_dim=512, num_layers=6, nhead=8, temporal_chunk_size=50\n",
    ").cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# In training loop\n",
    "for states_batch, targets_batch, actions_batch in dataloader:\n",
    "    states_batch = states_batch.cuda()  # (B, T, 6)\n",
    "    targets_batch = targets_batch.cuda()  # (B, T, 3)  ← repeated goal\n",
    "    actions_batch = actions_batch.cuda()  # (B, T, 3)\n",
    "\n",
    "    loss = model.get_chunked_loss(states_batch, targets_batch, actions_batch, chunk_size=50)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "all_results = {}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    # Create model\n",
    "    model_class = config['class']\n",
    "    model_params = config['params']\n",
    "    model = model_class(**model_params).to(DEVICE)\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\n{model_name} - Parameters: {total_params:,}\")\n",
    "\n",
    "    # Train model\n",
    "    results = train_model(model_name, model, train_loader, test_loader, num_epochs=50)\n",
    "    all_results[model_name] = results\n",
    "\n",
    "print(\"\\n=== Training Complete ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Export comprehensive results\n",
    "for model_name, results in all_results.items():\n",
    "    # Save detailed results as JSON\n",
    "    results_file = f'results/{model_name}_results.json'\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        json_results = results.copy()\n",
    "        if 'best_mse_results' in json_results and json_results['best_mse_results']:\n",
    "            json_results['best_mse_results'].pop('predictions', None)\n",
    "            json_results['best_mse_results'].pop('targets', None)\n",
    "        if 'best_mae_results' in json_results and json_results['best_mae_results']:\n",
    "            json_results['best_mae_results'].pop('predictions', None)\n",
    "            json_results['best_mae_results'].pop('targets', None)\n",
    "        json.dump(json_results, f, indent=2)\n",
    "\n",
    "    print(f\"Results saved to: {results_file}\")\n",
    "\n",
    "# Export summary table\n",
    "summary_data = []\n",
    "for model_name, results in all_results.items():\n",
    "    row = {\n",
    "        'model_type': model_name,\n",
    "        'hyperparameters': results['hyperparameters'],\n",
    "        'best_mse_loss': results.get('best_mse_results', {}).get('loss', 'N/A'),\n",
    "        'best_mae_loss': results.get('best_mae_results', {}).get('loss', 'N/A'),\n",
    "        'best_mse_mse': results.get('best_mse_results', {}).get('mse', 'N/A'),\n",
    "        'best_mae_mae': results.get('best_mae_results', {}).get('mae', 'N/A'),\n",
    "        'epochs_trained': len(results['training_history'])\n",
    "    }\n",
    "    summary_data.append(row)\n",
    "\n",
    "with open('results/training_summary.json', 'w') as f:\n",
    "    json.dump(summary_data, f, indent=2)\n",
    "\n",
    "print(\"Summary saved to: results/training_summary.json\")\n",
    "\n",
    "# Export model weights (already saved during training)\n",
    "print(\"Model weights saved as .pth files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, (model_name, results) in enumerate(all_results.items()):\n",
    "    history = results['training_history']\n",
    "\n",
    "    epochs = [h['epoch'] for h in history]\n",
    "    mse_losses = [h['test_loss_mse'] for h in history]\n",
    "    mae_losses = [h['test_loss_mae'] for h in history]\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, mse_losses, label=model_name)\n",
    "    plt.title('MSE Loss vs Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, mae_losses, label=model_name)\n",
    "    plt.title('MAE Loss vs Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE Loss')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final results summary\n",
    "print(\"\\n=== Final Results Summary ===\")\n",
    "print(f\"{'Model':<12} {'MSE Loss':<10} {'MAE Loss':<10} {'MSE':<10} {'MAE':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, results in all_results.items():\n",
    "    mse_results = results.get('best_mse_results', {})\n",
    "    mae_results = results.get('best_mae_results', {})\n",
    "\n",
    "    mse_loss = f\"{mse_results.get('loss', 'N/A'):.6f}\" if mse_results else 'N/A'\n",
    "    mae_loss = f\"{mae_results.get('loss', 'N/A'):.6f}\" if mae_results else 'N/A'\n",
    "    mse_val = f\"{mse_results.get('mse', 'N/A'):.6f}\" if mse_results else 'N/A'\n",
    "    mae_val = f\"{mae_results.get('mae', 'N/A'):.6f}\" if mae_results else 'N/A'\n",
    "\n",
    "    print(f\"{model_name:<12} {mse_loss:<10} {mae_loss:<10} {mse_val:<10} {mae_val:<10}\")\n",
    "\n",
    "print(\"\\nModel weights saved as .pth files\")\n",
    "print(\"Detailed results saved in results/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file for easy download\n",
    "!zip -r mpc_surrogate_results.zip results/ *.pth\n",
    "\n",
    "from google.colab import files\n",
    "files.download('mpc_surrogate_results.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpc_surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
